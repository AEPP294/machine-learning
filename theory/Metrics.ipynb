{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "p = os.path.join(os.path.dirname('__file__'), '..')\n",
    "sys.path.append(p)\n",
    "from common import *\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn import metrics as scipy_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification\n",
    "* Accuracy\n",
    "* Precision/Recall\n",
    "* Confusion Matrix\n",
    "* ROC Curve\n",
    "\n",
    "Regression\n",
    "* Estimators have a score method providing a default evaluation criterion for the problem they are designed to solve\n",
    "* http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Unsupervised\n",
    "* Pairwise Distance\n",
    "* Euclidian Distance\n",
    "* Jaccardian Distance\n",
    "* Cosine Similarity\n",
    "* ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([1,0,1,0,1,0,1,0,0])\n",
    "targ = np.array([1,1,1,0,0,0,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "# Variance in the dependent variable predictable from the independent variable(s)\n",
    "# i.e. how predictive is your independent variable?\n",
    "# High R^2 = very predictive\n",
    "# 1 = perfect match\n",
    "# 0 = model no better than taking the mean of dataset\n",
    "# <0 = model worse than mean of dataset\n",
    "\n",
    "# R^2 measures how well a model performs relative to a simple mean of the target values\n",
    "# What would be our score if we just took the mean of the targets?\n",
    "# Compares YOUR predictions to a baseline (mean target value -- always guess Blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, targets):\n",
    "    # How many predicted labels = target labels?\n",
    "    return sklearn.metrics.accuracy_score(targets.flatten(), preds.flatten())\n",
    "\n",
    "def recall(preds, targets):\n",
    "    # Of the positive cases, how many do you catch?\n",
    "    return sklearn.metrics.recall_score(targets.flatten(), preds.flatten())\n",
    "\n",
    "def precision(preds, targets):\n",
    "    # If you guess positive, how often are you right?\n",
    "    return sklearn.metrics.precision_score(targets.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5555555555555556 \n",
      "Recall 0.5 \n",
      "Precision 0.75\n"
     ]
    }
   ],
   "source": [
    "acc = sklearn.metrics.accuracy_score(targ, pred)\n",
    "recall = sklearn.metrics.recall_score(targ, pred)\n",
    "precision = sklearn.metrics.precision_score(targ, pred)\n",
    "\n",
    "print(\"Accuracy\", acc, \"\\nRecall\", recall, \"\\nPrecision\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n",
    "* http://binf.gmu.edu/mmasso/ROC101.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restricted to the binary classification task\n",
    "# or multilabel classification task in label indicator format?\n",
    "\n",
    "probs = np.array([1,0,1,0,1,0,1,0,0])\n",
    "targ = np.array([1,1,1,0,0,0,1,1,1])\n",
    "\n",
    "scipy_metrics.roc_auc_score(targ, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP/TN/FP/FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 2 3\n"
     ]
    }
   ],
   "source": [
    "TP = ((pred == targ) & (pred == 1)).sum()\n",
    "\n",
    "FP = ((pred != targ) & (pred == 1)).sum()\n",
    "\n",
    "TN = ((pred == targ) & (pred == 0)).sum()\n",
    "\n",
    "FN = ((pred != targ) & (pred == 0)).sum()\n",
    "\n",
    "print(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1846304dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(targ, pred)\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False)\n",
    "\n",
    "plt.ylabel('target') # rows\n",
    "plt.xlabel('pred'); # cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.67      0.50         3\n",
      "          1       0.75      0.50      0.60         6\n",
      "\n",
      "avg / total       0.63      0.56      0.57         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nice helper function for: Precision, Recall, F1, Support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targ, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combines Precision / Recall into one useful metric\n",
    "* F1-Score = weights Precision and Recall equally\n",
    "* F2-Score = overweights Recall\n",
    "* Harmonic Mean\n",
    "    * Averaging Ratios\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html\n",
    "* https://www.quora.com/What-is-an-intuitive-explanation-of-F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.6 \n",
      "F2 0.54\n"
     ]
    }
   ],
   "source": [
    "# Beta = 1 weights precision/recall equally\n",
    "f1 = sklearn.metrics.fbeta_score(targ, pred, beta=1, average='binary')\n",
    "\n",
    "# Beta = 2 overweights recall\n",
    "f2 = sklearn.metrics.fbeta_score(targ, pred, beta=2, average='binary')\n",
    "\n",
    "print(\"F1\", f1, \"\\nF2\", round(f2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
